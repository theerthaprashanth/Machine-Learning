{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fe0bc413f17732e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T05:58:47.791935Z",
     "start_time": "2025-11-05T05:58:45.294542Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "!pip install scikit-learn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def gradient_descent(x, y):\n",
    "    m_curr = b_curr = 0             # initialize slope and intercept\n",
    "    iterations = 10000              # max iterations\n",
    "    n = len(x)                      # number of data points\n",
    "    learning_rate = 0.0001\n",
    "    prev_cost = float('inf')        # store previous cost for convergence check\n",
    "\n",
    "    for i in range(iterations):\n",
    "        y_predicted = m_curr * x + b_curr\n",
    "        cost = (1/n) * sum((y - y_predicted) ** 2)\n",
    "\n",
    "        # stop early if cost hasn't changed much\n",
    "        if math.isclose(cost, prev_cost, rel_tol=1e-5):\n",
    "            print(f\"Cost converged at iteration {i}\")\n",
    "            break\n",
    "\n",
    "        # compute gradients\n",
    "        md = -(2/n) * sum(x * (y - y_predicted))\n",
    "        bd = -(2/n) * sum(y - y_predicted)\n",
    "\n",
    "        # update m and b\n",
    "        m_curr = m_curr - learning_rate * md\n",
    "        b_curr = b_curr - learning_rate * bd\n",
    "\n",
    "        prev_cost = cost\n",
    "        return m_curr, b_curr\n",
    "\n",
    "    # simplified final print\n",
    "    print(\"Final m and b:\", m_curr, b_curr)\n",
    "\n",
    "# read CSV file\n",
    "data = pd.read_csv('test_scores.csv')\n",
    "\n",
    "# extract columns\n",
    "x = np.array(data['math'])\n",
    "y = np.array(data['cs'])\n",
    "#return m_curr, b_curr\n",
    "# run gradient descent\n",
    "gd_m, gd_b = gradient_descent(x, y)\n",
    "reg = LinearRegression()\n",
    "reg.fit(x, y)\n",
    "sklearn_coef = reg.coef_[0]\n",
    "sklearn_intercept = reg.intercept_\n",
    "print(\"\\nComparison:\")\n",
    "print(\"Difference in slope:\", abs(sklearn_coef - gd_m))\n",
    "print(\"Difference in intercept:\", abs(sklearn_intercept - gd_b))\n"
   ],
   "id": "bbe2396fb99dc899",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\theertha.p\\pycharmmiscproject\\.venv\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\theertha.p\\pycharmmiscproject\\.venv\\lib\\site-packages (from scikit-learn) (2.3.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\theertha.p\\pycharmmiscproject\\.venv\\lib\\site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\theertha.p\\pycharmmiscproject\\.venv\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\theertha.p\\pycharmmiscproject\\.venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[92 56 88 70 80 49 65 35 66 67].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[51]\u001B[39m\u001B[32m, line 47\u001B[39m\n\u001B[32m     45\u001B[39m gd_m, gd_b = gradient_descent(x, y)\n\u001B[32m     46\u001B[39m reg = LinearRegression()\n\u001B[32m---> \u001B[39m\u001B[32m47\u001B[39m \u001B[43mreg\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     48\u001B[39m sklearn_coef = reg.coef_[\u001B[32m0\u001B[39m]\n\u001B[32m     49\u001B[39m sklearn_intercept = reg.intercept_\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001B[39m, in \u001B[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(estimator, *args, **kwargs)\u001B[39m\n\u001B[32m   1358\u001B[39m     estimator._validate_params()\n\u001B[32m   1360\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[32m   1361\u001B[39m     skip_parameter_validation=(\n\u001B[32m   1362\u001B[39m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[32m   1363\u001B[39m     )\n\u001B[32m   1364\u001B[39m ):\n\u001B[32m-> \u001B[39m\u001B[32m1365\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:618\u001B[39m, in \u001B[36mLinearRegression.fit\u001B[39m\u001B[34m(self, X, y, sample_weight)\u001B[39m\n\u001B[32m    614\u001B[39m n_jobs_ = \u001B[38;5;28mself\u001B[39m.n_jobs\n\u001B[32m    616\u001B[39m accept_sparse = \u001B[38;5;28;01mFalse\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.positive \u001B[38;5;28;01melse\u001B[39;00m [\u001B[33m\"\u001B[39m\u001B[33mcsr\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mcsc\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mcoo\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m--> \u001B[39m\u001B[32m618\u001B[39m X, y = \u001B[43mvalidate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    619\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    620\u001B[39m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    621\u001B[39m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    622\u001B[39m \u001B[43m    \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[43m=\u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    623\u001B[39m \u001B[43m    \u001B[49m\u001B[43my_numeric\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    624\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmulti_output\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    625\u001B[39m \u001B[43m    \u001B[49m\u001B[43mforce_writeable\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    626\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    628\u001B[39m has_sw = sample_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    629\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m has_sw:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2971\u001B[39m, in \u001B[36mvalidate_data\u001B[39m\u001B[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001B[39m\n\u001B[32m   2969\u001B[39m         y = check_array(y, input_name=\u001B[33m\"\u001B[39m\u001B[33my\u001B[39m\u001B[33m\"\u001B[39m, **check_y_params)\n\u001B[32m   2970\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m2971\u001B[39m         X, y = \u001B[43mcheck_X_y\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mcheck_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2972\u001B[39m     out = X, y\n\u001B[32m   2974\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params.get(\u001B[33m\"\u001B[39m\u001B[33mensure_2d\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1368\u001B[39m, in \u001B[36mcheck_X_y\u001B[39m\u001B[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[39m\n\u001B[32m   1362\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   1363\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m requires y to be passed, but the target y is None\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1364\u001B[39m     )\n\u001B[32m   1366\u001B[39m ensure_all_finite = _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001B[32m-> \u001B[39m\u001B[32m1368\u001B[39m X = \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1369\u001B[39m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1370\u001B[39m \u001B[43m    \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[43m=\u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1371\u001B[39m \u001B[43m    \u001B[49m\u001B[43maccept_large_sparse\u001B[49m\u001B[43m=\u001B[49m\u001B[43maccept_large_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1372\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1373\u001B[39m \u001B[43m    \u001B[49m\u001B[43morder\u001B[49m\u001B[43m=\u001B[49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1374\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcopy\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1375\u001B[39m \u001B[43m    \u001B[49m\u001B[43mforce_writeable\u001B[49m\u001B[43m=\u001B[49m\u001B[43mforce_writeable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1376\u001B[39m \u001B[43m    \u001B[49m\u001B[43mensure_all_finite\u001B[49m\u001B[43m=\u001B[49m\u001B[43mensure_all_finite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1377\u001B[39m \u001B[43m    \u001B[49m\u001B[43mensure_2d\u001B[49m\u001B[43m=\u001B[49m\u001B[43mensure_2d\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1378\u001B[39m \u001B[43m    \u001B[49m\u001B[43mallow_nd\u001B[49m\u001B[43m=\u001B[49m\u001B[43mallow_nd\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1379\u001B[39m \u001B[43m    \u001B[49m\u001B[43mensure_min_samples\u001B[49m\u001B[43m=\u001B[49m\u001B[43mensure_min_samples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1380\u001B[39m \u001B[43m    \u001B[49m\u001B[43mensure_min_features\u001B[49m\u001B[43m=\u001B[49m\u001B[43mensure_min_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1381\u001B[39m \u001B[43m    \u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m=\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1382\u001B[39m \u001B[43m    \u001B[49m\u001B[43minput_name\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mX\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1383\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1385\u001B[39m y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n\u001B[32m   1387\u001B[39m check_consistent_length(X, y)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1091\u001B[39m, in \u001B[36mcheck_array\u001B[39m\u001B[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[39m\n\u001B[32m   1084\u001B[39m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1085\u001B[39m             msg = (\n\u001B[32m   1086\u001B[39m                 \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mExpected 2D array, got 1D array instead:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33marray=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00marray\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m   1087\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mReshape your data either using array.reshape(-1, 1) if \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1088\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33myour data has a single feature or array.reshape(1, -1) \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1089\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mif it contains a single sample.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1090\u001B[39m             )\n\u001B[32m-> \u001B[39m\u001B[32m1091\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n\u001B[32m   1093\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m dtype_numeric \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(array.dtype, \u001B[33m\"\u001B[39m\u001B[33mkind\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m array.dtype.kind \u001B[38;5;129;01min\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mUSV\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m   1094\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   1095\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mdtype=\u001B[39m\u001B[33m'\u001B[39m\u001B[33mnumeric\u001B[39m\u001B[33m'\u001B[39m\u001B[33m is not compatible with arrays of bytes/strings.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1096\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mConvert your data to numeric values explicitly instead.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1097\u001B[39m     )\n",
      "\u001B[31mValueError\u001B[39m: Expected 2D array, got 1D array instead:\narray=[92 56 88 70 80 49 65 35 66 67].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "execution_count": 51
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
